{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import pickle\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= \"D:/Dataset_Siswa.csv\"\n",
    "df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID       Label  Nilai_Matematika  Nilai_Biologi  Nilai_Fisika  \\\n",
      "0  M001  Matematika                86             67            74   \n",
      "1  M002  Matematika                81             67            77   \n",
      "2  M003  Matematika                85             68            72   \n",
      "3  M004  Matematika                82             65            76   \n",
      "4  M005  Matematika                82             65            74   \n",
      "\n",
      "   Nilai_Kimia   Nilai_English  Kognitif_Skills  Creativity_Innovation  \\\n",
      "0            75             74               99                     70   \n",
      "1            70             72               94                     75   \n",
      "2            71             78               93                     70   \n",
      "3            73             73               87                     79   \n",
      "4            69             72               93                     74   \n",
      "\n",
      "   Communication_Collaboration  Adaptation_DecisionMaking  \\\n",
      "0                           73                         76   \n",
      "1                           68                         85   \n",
      "2                           67                         81   \n",
      "3                           66                         85   \n",
      "4                           65                         84   \n",
      "\n",
      "   Tech_Coding_Interest  Research_Data_Interest  Problem_Solving_Interest   \\\n",
      "0                     1                       1                          1   \n",
      "1                     1                       0                          1   \n",
      "2                     1                       1                          1   \n",
      "3                     1                       0                          0   \n",
      "4                     1                       1                          0   \n",
      "\n",
      "   Creative_Social_Skills   Field_Work_Interest   Leadership_Skills   \\\n",
      "0                        0                     0                   0   \n",
      "1                        0                     0                   0   \n",
      "2                        0                     0                   0   \n",
      "3                        0                     0                   0   \n",
      "4                        1                     0                   1   \n",
      "\n",
      "   Preference for Practical Work  \n",
      "0                              1  \n",
      "1                              0  \n",
      "2                              0  \n",
      "3                              1  \n",
      "4                              0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   ID                             5000 non-null   object\n",
      " 1   Label                          5000 non-null   object\n",
      " 2   Nilai_Matematika               5000 non-null   int64 \n",
      " 3   Nilai_Biologi                  5000 non-null   int64 \n",
      " 4   Nilai_Fisika                   5000 non-null   int64 \n",
      " 5   Nilai_Kimia                    5000 non-null   int64 \n",
      " 6   Nilai_English                  5000 non-null   int64 \n",
      " 7   Kognitif_Skills                5000 non-null   int64 \n",
      " 8   Creativity_Innovation          5000 non-null   int64 \n",
      " 9   Communication_Collaboration    5000 non-null   int64 \n",
      " 10  Adaptation_DecisionMaking      5000 non-null   int64 \n",
      " 11  Tech_Coding_Interest           5000 non-null   int64 \n",
      " 12  Research_Data_Interest         5000 non-null   int64 \n",
      " 13  Problem_Solving_Interest       5000 non-null   int64 \n",
      " 14  Creative_Social_Skills         5000 non-null   int64 \n",
      " 15  Field_Work_Interest            5000 non-null   int64 \n",
      " 16  Leadership_Skills              5000 non-null   int64 \n",
      " 17  Preference for Practical Work  5000 non-null   int64 \n",
      "dtypes: int64(16), object(2)\n",
      "memory usage: 703.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler loaded successfully: <class 'sklearn.preprocessing._data.MinMaxScaler'>\n",
      "Label Encoder loaded successfully: <class 'sklearn.preprocessing._label.LabelEncoder'>\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and labels (y)\n",
    "X = df.drop(columns=['ID', 'Label'], axis=1).values  # Drop ID and Label columns\n",
    "y = df['Label'].values  # The target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "timesteps = 1\n",
    "X_train = X_train.reshape(X_train.shape[0], timesteps, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], timesteps, X_test.shape[1])\n",
    "\n",
    "# Scale the data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "# Save the scaler for later use in the Flask app\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Verify that the scaler file was saved\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    loaded_scaler = pickle.load(f)\n",
    "print(\"Scaler loaded successfully:\", type(loaded_scaler))\n",
    "\n",
    "# Convert labels to strings and encode them\n",
    "y_train = y_train.astype(str)\n",
    "y_test = y_test.astype(str)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Save the label encoder for use in the Flask app\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Verify that the label encoder file was saved\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    loaded_label_encoder = pickle.load(f)\n",
    "print(\"Label Encoder loaded successfully:\", type(loaded_label_encoder))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.3094 - loss: 2.1621 - val_accuracy: 0.6889 - val_loss: 1.3986\n",
      "Epoch 2/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6920 - loss: 1.1830 - val_accuracy: 0.8022 - val_loss: 0.7523\n",
      "Epoch 3/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8193 - loss: 0.6676 - val_accuracy: 0.8422 - val_loss: 0.5228\n",
      "Epoch 4/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8749 - loss: 0.4515 - val_accuracy: 0.8756 - val_loss: 0.4001\n",
      "Epoch 5/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8963 - loss: 0.3628 - val_accuracy: 0.8956 - val_loss: 0.3310\n",
      "Epoch 6/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9083 - loss: 0.3076 - val_accuracy: 0.9133 - val_loss: 0.2890\n",
      "Epoch 7/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9221 - loss: 0.2646 - val_accuracy: 0.9156 - val_loss: 0.2625\n",
      "Epoch 8/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.2315 - val_accuracy: 0.9267 - val_loss: 0.2312\n",
      "Epoch 9/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9392 - loss: 0.2051 - val_accuracy: 0.9200 - val_loss: 0.2280\n",
      "Epoch 10/10\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.1926 - val_accuracy: 0.9378 - val_loss: 0.2041\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9546 - loss: 0.1644\n",
      "Test Loss: 0.1689370572566986\n",
      "Test Accuracy: 0.9599999785423279\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model for later use in the Flask app\n",
    "model.save('model.keras')  # Save as Keras .keras format\n",
    "\n",
    "# Optionally save in the H5 format too\n",
    "model.save('model.h5')  # Save as .h5 format\n",
    "\n",
    "# Save the model architecture as JSON\n",
    "model_json = model.to_json()  # Get model architecture in JSON format\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save the entire model using pickle (if needed)\n",
    "with open('model.bin', 'wb') as bin_file:\n",
    "    pickle.dump(model, bin_file)  # Save as .bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.3.200:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [05/Dec/2024 12:42:08] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [05/Dec/2024 12:42:54] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [05/Dec/2024 12:43:25] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [05/Dec/2024 12:44:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [05/Dec/2024 12:45:27] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model, scaler, and label encoder\n",
    "model = tf.keras.models.load_model('model.keras')\n",
    "\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# Route for prediction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Check if the 'input' field is in the request data\n",
    "        data = request.get_json()\n",
    "\n",
    "        if 'input' not in data:\n",
    "            return jsonify({'error': 'No input data provided'}), 400\n",
    "\n",
    "        # Input data should be a list (e.g., [1.0, 2.0, 3.0])\n",
    "        input_data = np.array(data['input'])\n",
    "        if len(input_data.shape) != 1:\n",
    "            return jsonify({'error': 'Input data should be a 1D list of numerical values'}), 400\n",
    "\n",
    "        # Reshape the input data for LSTM (1, 1, n_features)\n",
    "        input_data = input_data.reshape(1, 1, len(input_data))\n",
    "\n",
    "        # Scale the input data using the saved scaler\n",
    "        input_data_scaled = scaler.transform(input_data.reshape(-1, input_data.shape[-1])).reshape(input_data.shape)\n",
    "\n",
    "        # Make the prediction using the model\n",
    "        prediction = model.predict(input_data_scaled)\n",
    "\n",
    "        # Decode the predicted label from one-hot encoding\n",
    "        predicted_label = np.argmax(prediction, axis=1)\n",
    "        predicted_label = label_encoder.inverse_transform(predicted_label)\n",
    "\n",
    "        # Return the prediction as JSON response\n",
    "        return jsonify({'predicted_label': predicted_label[0]})\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch all unexpected errors and return them as a response\n",
    "        return jsonify({'error': f'An error occurred: {str(e)}'}), 500\n",
    "if __name__ == '__main__':\n",
    "    # Set debug=False for production\n",
    "    app.run(debug=False, host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://192.168.1.5:5001\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 18:15:28] \"GET /download_model/model.h5 HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 18:16:24] \"GET /download_model/model.keras HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 18:16:31] \"\u001b[31m\u001b[1mGET /download_model/model.keras HTTP/1.1\u001b[0m\" 400 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "app.has_route = set()  # Initialize a set to keep track of defined routes\n",
    "\n",
    "@app.route('/download_model/<filename>')\n",
    "def download_model(filename):\n",
    "    try:\n",
    "        # Check if the route for the file is already defined\n",
    "        if filename in app.has_route:\n",
    "            return f\"Error: The route for {filename} is already defined.\", 400\n",
    "\n",
    "        # Check if the file exists\n",
    "        file_path = os.path.join(os.getcwd(), filename)  # Adjust the path as needed\n",
    "        if os.path.exists(file_path):\n",
    "            app.has_route.add(filename)  # Add the filename to the set\n",
    "            return send_file(file_path, as_attachment=True)\n",
    "        else:\n",
    "            return f\"Error: {filename} not found.\", 404\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", 500\n",
    "\n",
    "# Route to download scaler.pkl\n",
    "@app.route('/download/scaler', methods=['GET'])\n",
    "def download_scaler():\n",
    "    file_path = os.path.join(os.getcwd(), 'scaler.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        return send_file(file_path, as_attachment=True)\n",
    "    else:\n",
    "        return jsonify({'error': 'scaler.pkl not found'}), 404\n",
    "\n",
    "# Route to download label_encoder.pkl\n",
    "@app.route('/download/label_encoder', methods=['GET'])\n",
    "def download_label_encoder():\n",
    "    file_path = os.path.join(os.getcwd(), 'label_encoder.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        return send_file(file_path, as_attachment=True)\n",
    "    else:\n",
    "        return jsonify({'error': 'label_encoder.pkl not found'}), 404\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set debug=False for production\n",
    "    app.run(debug=False, host='0.0.0.0', port=5001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
